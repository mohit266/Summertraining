{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Notes",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7LL4r2I3pDZZ",
        "colab_type": "text"
      },
      "source": [
        "                       Day 22 : Web Scrapping\n",
        "\n",
        "* Web Scrapping means scrapping web data from websites leagally or illegally.\n",
        "* Scrap means Kachra.\n",
        "* The art of extracting useful data from web scrap data is called as Web Scrapping.\n",
        "* To scrap data we use some liberaries to scrap data like Beautiful Soup\n",
        "* To install beautiful soup we use"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "seu-CfF1pA_d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pip3 install bs4"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Rf-wNIYppd0",
        "colab_type": "text"
      },
      "source": [
        "* Now first we need a request model to download web data using http/tcp protocol.\n",
        "* To use this we need a liberary called requests\n",
        "* To install requests model use"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lzSP-VfYpuyd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pip3 install requests"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wLbEqbl1pzFK",
        "colab_type": "text"
      },
      "source": [
        "* Now Lets begin with importing the liberaries."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JAv9U8Rjpx-z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import request\n",
        "from bs4 import BeautifulSoup as bsf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sV3DXa6Up_O_",
        "colab_type": "text"
      },
      "source": [
        "* Now to create request we need a weburl"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYQyU7afp8TO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "url = \"https://en.wikipedia.org/wiki/Death\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DTsp0dXQqEjx",
        "colab_type": "text"
      },
      "source": [
        "* We are sending requiest to the url and taking the response"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "41div-g-qHsw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "response = requests.get(url)\n",
        "response\n",
        "<Response [200]>"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ka-Pz0TGqOTj",
        "colab_type": "text"
      },
      "source": [
        "* To display all the text we use .text This will show all html data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxgVaUrbqLkX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "response.text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ScebpBjqUM-",
        "colab_type": "text"
      },
      "source": [
        "* Now we need an HTML parser for extracting and formatting HTML Data from webpage therefore we need to install the parser lxml"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xqi5d8laqTis",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip3 install lxml"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9AAGoOJtqUrn",
        "colab_type": "text"
      },
      "source": [
        "* Now we will use bsf, response and the parser to store web parsed data in a variable"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Dwr359fqVLh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "soup = bsf(response.text,\"lxml\")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}